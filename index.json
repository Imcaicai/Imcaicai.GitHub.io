[{"categories":["Tech"],"content":"本文为论文：Vision GNN: An Image is Worth Graph of Nodes 的阅读笔记。 论文下载 ","date":"2022-10-17","objectID":"/an-image-is-worth-graph-of-nodes/:0:0","tags":["深度学习"],"title":"Vision GNN: An Image is Worth Graph of Nodes","uri":"/an-image-is-worth-graph-of-nodes/"},{"categories":["Tech"],"content":"引言 网络架构在基于深度学习的计算机视觉中起着关键作用。广泛使用的CNN和 transformer（变换器）将图像视为 grid（网格）或 sequence（序列）结构，这对于捕捉不规则、复杂的物体来说是不灵活的。本文建议将图像表示为一个 graph 结构，并引入一个新的 Vision GNN（ViG）架构来提取视觉任务的图层特征。 文章主要工作： 介绍了计算机视觉方面的现有模型方法和成果 介绍ViG模型的构建过程及工作原理，为未来的研究提供有用的灵感和经验 通过图像分类和物体检测实验证明了ViG模型在视觉任务中的有效性 ViG包括两个基本模块。图形模块具有图形卷积功能，用于聚合和更新图形信息。更新图信息的Grapher模块，以及带有两个线性层的FFN模块，用于节点特征转换。特征转换。ViG的各向同性和金字塔结构都是以不同的模型尺寸建立的。不同的模型大小。在图像识别和物体检测任务上进行了大量的实验，证明了我们的方法的优越性。在图像识别和物体检测任务上的大量实验证明了我们的ViG架构的优越性。我们希望这个在一般视觉任务上对GNN的开创性研究将为未来的研究提供有用的灵感和经验。为未来的研究提供有用的灵感和经验。 ","date":"2022-10-17","objectID":"/an-image-is-worth-graph-of-nodes/:1:0","tags":["深度学习"],"title":"Vision GNN: An Image is Worth Graph of Nodes","uri":"/an-image-is-worth-graph-of-nodes/"},{"categories":["Tech"],"content":"相关研究 CNN 曾经是计算机视觉中标准的网络结构，但近来 transformer with attention mechanism 、MLP-based 等模型也在不断发展，这些正在将视觉模型推向一个前所未有的高度。 ","date":"2022-10-17","objectID":"/an-image-is-worth-graph-of-nodes/:2:0","tags":["深度学习"],"title":"Vision GNN: An Image is Worth Graph of Nodes","uri":"/an-image-is-worth-graph-of-nodes/"},{"categories":["Tech"],"content":"3种图像结构 不同的网络结构以不同的方式处理输入的图像，通常有 grid structure, sequence structure, graph structure 3种，如下图所示。在 grid structure 和 sequence structure 中，节点只按空间位置排序；在 graph structure 中，节点是通过其内容连接的，不受局部位置的限制。 CNN 在图像上应用滑动窗口，并引入移位变异性和位置性；最近的 vision transformer 或 MLP 将图像视为 a sequence of patches（补丁序列）。 由于物体形状通常不是规则的四边形，常用的 grid 或 sequence 结构处理起图像来不够灵活，所以在本文中采用 graph structure 。 ","date":"2022-10-17","objectID":"/an-image-is-worth-graph-of-nodes/:2:1","tags":["深度学习"],"title":"Vision GNN: An Image is Worth Graph of Nodes","uri":"/an-image-is-worth-graph-of-nodes/"},{"categories":["Tech"],"content":"3种模型 CNN：曾经是计算机视觉中的主流网络结构，已经成功地应用于各种视觉任务，如图像分类、物体检测和语义分割。CNN模型在过去的十年里发展迅速，代表性的作品包括ResNet、MobileNet和NAS。 Vision transformer：从2020年开始，被引入到视觉任务中。从那时起起，ViT的一些变体被提出来以提高视觉任务的性能。主要的改进包括金字塔结，局部注意和位置编码。 MLP：通过专门设计的模块，MLP可以达到有竞争力的性能，并且在一般的视觉任务（如物体检测和分割）上工作。 ","date":"2022-10-17","objectID":"/an-image-is-worth-graph-of-nodes/:2:2","tags":["深度学习"],"title":"Vision GNN: An Image is Worth Graph of Nodes","uri":"/an-image-is-worth-graph-of-nodes/"},{"categories":["Tech"],"content":"GNN模型 1. GNN\u0026GCN GNN：图神经网络，由于传统的CNN网络无法表示顶点和边这种关系型数据，便出现了图神经网络解决这种图数据的表示问题，这属于CNN往图方向的应用扩展 GCN：图卷积神经网络，GNN在训练过程中，有将attention引入图结构的，有将门控机制引入图结构的，还有将卷积引入图结构的，引入卷积的GNN就是GCN，通过提取空间特征来进行学习 2. 发展 Micheli提出了早期的提出了早期的基于空间的GCN，Bruna等人提出了基于频谱的GCN，近几年来基于这两种GCN的改进和扩展也被提出。 3. 应用 GCN通常被应用于图数据，如社会网络、引文网络和生化图；在计算机视觉领域的应用主要包括点云分类、场景图生成和动作识别。 GCN只能解决自然形成的图的特定视觉任务，对于计算机视觉的一般应用，我们需要一个基于GCN的骨干网络来直接处理图像数据。 ","date":"2022-10-17","objectID":"/an-image-is-worth-graph-of-nodes/:2:3","tags":["深度学习"],"title":"Vision GNN: An Image is Worth Graph of Nodes","uri":"/an-image-is-worth-graph-of-nodes/"},{"categories":["Tech"],"content":"ViG模型 ViG模型的处理流程如下： ","date":"2022-10-17","objectID":"/an-image-is-worth-graph-of-nodes/:3:0","tags":["深度学习"],"title":"Vision GNN: An Image is Worth Graph of Nodes","uri":"/an-image-is-worth-graph-of-nodes/"},{"categories":["Tech"],"content":"模型构建(Image→Graph) 首先基于 graph structure 建立视觉图形神经网络，用于视觉任务。将输入的图像划分为若干个 patches（补丁），并将每个斑块视为一个 node （节点）。（不用像素当做节点的原因：会导致节点过多） 对于一个大小为 $H×W×3$ 的图像，我们将其分为 N 个补丁，把每个补丁转化为一个特征向量 $x_i∈R^D$，得到 $X = [x_1,x_2,…,x_N ]$， 其中 $D$ 是特征维度。将特征看做无序节点$V={v_1,v_2,…,v_N}$，节点$v_i$的k邻近节点记为$N(v_i)$，对每个$v_j∈N(v_i)$添加$v_j$到$v_i$的边$e_ji$，从而得到图$G = (V,E) $，我们把图的构建过程记为$G = G(X)$。 ","date":"2022-10-17","objectID":"/an-image-is-worth-graph-of-nodes/:3:1","tags":["深度学习"],"title":"Vision GNN: An Image is Worth Graph of Nodes","uri":"/an-image-is-worth-graph-of-nodes/"},{"categories":["Tech"],"content":"模型处理 ","date":"2022-10-17","objectID":"/an-image-is-worth-graph-of-nodes/:3:2","tags":["深度学习"],"title":"Vision GNN: An Image is Worth Graph of Nodes","uri":"/an-image-is-worth-graph-of-nodes/"},{"categories":["Tech"],"content":"基本模块 图形器和FFN(feed-forward network)模块。图形模块是在图卷积的基础上构建的。 图形信息处理。为了缓解传统GNN的过度平滑现象。 FFN模块用于节点特征转换和鼓励节点多样性。利用 Grapher和FFN模块，我们以各向同性和金字塔的方式建立我们的ViG模型。 ","date":"2022-10-17","objectID":"/an-image-is-worth-graph-of-nodes/:3:3","tags":["深度学习"],"title":"Vision GNN: An Image is Worth Graph of Nodes","uri":"/an-image-is-worth-graph-of-nodes/"},{"categories":["Tech"],"content":"模型优点 graph 是广义的数据结构，grid 和 sequence 可以看做 graph 的特例 graph 更灵活，可以对复杂、不规则的物体进行建模 一个物体可以被看作是由各个部分组成的，graph 结构可以构建他们的联系 ","date":"2022-10-17","objectID":"/an-image-is-worth-graph-of-nodes/:3:4","tags":["深度学习"],"title":"Vision GNN: An Image is Worth Graph of Nodes","uri":"/an-image-is-worth-graph-of-nodes/"},{"categories":["Tech"],"content":"实验 在实验中，我们证明了ViG模型在视觉任务中的有效性，如图像分类 和物体检测。例如，我们的金字塔型ViG-S在ImageNet分类任务中达到了82.1%的最高准确率。 分类任务中取得了82.1%的最高准确率，超过了具有代表性的CNN（ResNet[16]）、MLP（CycleMLP[4]）和变换器（Swin-T[4]）。 和变换器（Swin-T[33]）的FLOPs相似（约4.5G）。 ","date":"2022-10-17","objectID":"/an-image-is-worth-graph-of-nodes/:4:0","tags":["深度学习"],"title":"Vision GNN: An Image is Worth Graph of Nodes","uri":"/an-image-is-worth-graph-of-nodes/"},{"categories":["Tech"],"content":"1 结构 go run helloworld.go：执行Go代码 go build helloworld.go：编译生成二进制文件 ./helloworld：运行 import 声明必须跟在文件的 package 声明之后 Go 语言不需要在语句或者声明的末尾添加分号，除非一行上有多条语句 函数的左括号 { 必须和 func 函数声明在同一行上，且位于末尾，不能独占一行 在表达式 x+y 中，可在 + 后换行，不能在 + 前换行 2 基础语法 //格式化字符串 var stockcode = 123 var enddate = \"2020-12-31\" var url = \"Code=%d\u0026endDate=%s\" var target_url = fmt.Sprintf(url, stockcode, enddate) fmt.Println(target_url) 3 语言类型 布尔型 数字型 整形：int uint 浮点型：float complex 字符串 派生类型 4 变量 变量声明 var identifier type（指定变量类型，如果没有初始化，则变量默认为零值 var v_name = value（根据值自行判断变量类型 v_name := value（只能在函数体中出现 // 这种因式分解关键字的写法一般用于声明全局变量 var ( vname1 v_type1 vname2 v_type2 ) 局部变量不允许声明但不使用，全局变量可以 a, b = b, a （简单交换2个变量 _：空白标识符，也用于被抛弃值 5 常量 const identifier [type] = value //用作枚举 const ( Unknown = 0 Female = 1 Male = 2 ) 常量可以用len(), cap(), unsafe.Sizeof()函数计算表达式的值（必须是内置函数 iota 在const关键字出现时将被重置为0，const中每新增一行常量声明将使 iota 计数一次 6 条件语句 switch 匹配项后面也不需要再加 break fallthrough 执行后面的case case后面是类型不被局限于常量或整数，可以加多个，必须类型相同 func main() { var grade string = \"B\" var marks int = 90 switch marks { case 90: grade = \"A\" case 80,70: grade = \"B\" default: grade = \"D\" } switch { case grade == \"A\": fmt.Println(\"youxiu\") case grade == \"B\", grade == \"C\": fmt.Println(\"lianghao\") default: fmt.Println(\"cha\") } } type switch 判断某个 interface 变量中实际存储的变量类型 select 通信的 switch 语句 7 循环语句 for循环 for init; condition; post { } for condition { } for { } //range格式可以对 slice、map、数组、字符串等进行迭代循环 for key, value := range oldMap { newMap[key] = value } for key := range oldMap for _, value := range oldMap 在多重循环中，可以用标号 label 标出想 break 的循环 在多重循环中，可以用标号 label 标出想 continue 的循环 goto 语句可以无条件地转移到过程中指定的行 8 函数 func function_name( [parameter list] ) [return_types] { 函数体 } 函数可作为实参 匿名函数，可作为闭包 //方法 func (variable_name variable_data_type) function_name() [return_type]{ /* 函数体*/ } 9 变量作用域 局部变量：作用域只在函数体内 全局变量：整个包甚至外部包（被导出后）使用 全局变量与局部变量名称可以相同，但是函数内的局部变量会被优先考虑 10 数组 var variable_name [SIZE] variable_type 可以使用 ... 代替数组的长度 // 将索引为 1 和 3 的元素初始化 balance := [...]float32{1:2.0,3:7.0} 多维数组 使用 append() 函数向空的二维数组添加两行一维数组 //多维数组 var variable_name [SIZE1][SIZE2]...[SIZEN] variable_type 可以创建各个维度元素数量不一致的多维数组 //向函数传递数组 void myFunction(param [10]int) { ... } 11 指针 var var_name *var-type 指针数组 var ptr [MAX]*int; 指向指针的指针 var ptr **int; 12 结构体 //定义结构体 type struct_variable_type struct { member definition ... member definition } //声明变量 variable_name := structure_variable_type {value1, value2...valuen} variable_name := structure_variable_type { key1: value1, key2: value2..., keyn: valuen} 访问结构体：结构体.成员名 结构体作为函数参数 结构体指针 //声明 var struct_pointer *Books 结构体指针用 . 访问结构体成员 13 切片(Slice) var identifier []type //定义切片 var slice1 []type = make([]type, len) //创建切片 make([]T, length, capacity) //capacity指定容量，为可选参数 s :=[] int {1,2,3 } //直接初始化切片 s := arr[:] //初始化切片 s，是数组 arr 的引用 s := arr[startIndex:endIndex] //将 arr 中从下标 startIndex 到 endIndex-1 下的元素创建为一个新的切片 len() 方法获取长度 cap() 可以测量切片最长可以达到多少 空切片(nil)：切片未初始化，默认为nil，长度为0 copy() 方法拷贝切片 append() 方法向切片追加新元素 14 范围(range) 关键字用于 for 循环中迭代数组(array)、切片(slice)、通道(channel)或集合(map)的元素 在数组和切片中它返回元素的索引和索引对应的值，在集合中返回 key-value 对 //读取key,value for key, value := range oldMap { newMap[key] = value } //只读取key for key := range oldMap //只读取value for _, value := range oldMap range也可以用来枚举 Unicode 字符串 15 集合(Map) 无序的键值对的集合 /* 声明变量，默认 map 是 nil */ var map_variable map[key_data_type]value_data_type /* 使用 make 函数 */ map_variable := make(map[key_data_type]value_data_type) delete() 函数用于删除集合的元素, 参数为 map 和其对应的 key 16 接口 /* 定义接口 */ type interface_name interface { method_name1 [return_type] method_name2 [return_type] ... method_namen [return_type] } /* 定义结构体 */ type struct_name struct { /* variables */ } /* 实现接口方法 */ func (struct_name_variable struct_name) method_name1() [return_type] { /* 方法实现 */ } ... func (struct_name_variable struct_name) method_namen() [return_type] { /* 方法实现*/ } 17 错误处理 type error interface { Error() string } func Sqrt(f float64) (float64, error) { if f \u003c 0 { return 0, errors.New(\"math: square root of negative number\") } // 实现 } 18 并发 //goroutine语法 go 函数名( 参数列表 ) 同一个程序","date":"2022-10-16","objectID":"/go/:0:0","tags":["Go"],"title":"Go基本语法","uri":"/go/"}]