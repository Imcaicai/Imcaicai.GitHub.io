# Vision GNN: An Image is Worth Graph of Nodes


本文为论文 ***Vision GNN: An Image is Worth Graph of Nodes*** 的阅读笔记。

论文下载：[https://arxiv.org/abs/2206.00272](https://arxiv.org/abs/2206.00272)

## 引言

网络架构在基于深度学习的计算机视觉中起着关键作用。广泛使用的`CNN`和 `transformer`（变换器）将图像视为 `grid`（网格）或 `sequence`（序列）结构，这对于捕捉不规则、复杂的物体来说是不灵活的。本文建议将图像表示为一个 `graph` 结构，并引入一个新的 `Vision GNN（ViG）`架构来提取视觉任务的图层特征。

文章主要工作：

- 介绍了计算机视觉方面的现有模型方法和成果
- 介绍ViG模型的构建过程及工作原理，为未来的研究提供有用的灵感和经验
- 通过图像分类和物体检测实验证明了ViG模型在视觉任务中的有效性

## 1 相关研究

`CNN` 曾经是计算机视觉中标准的网络结构，但近来 `transformer with attention mechanism` 、`MLP-based` 等模型也在不断发展，这些正在将视觉模型推向一个前所未有的高度。

### 1.1 3种图像结构

不同的网络结构以不同的方式处理输入的图像，通常有`grid`, `sequence` ,`graph` 3种，如下图所示。在 `grid ` 和 `sequence`  结构中，节点只按空间位置排序；在 `graph` 结构中，节点是通过其内容连接的，不受局部位置的限制。

![image1](/img/GNN/image1.png)

`CNN` 在图像上应用滑动窗口，并引入移位变异性和位置性；最近的 `vision transformer` 或 `MLP` 将图像视为 `a sequence of patches`（补丁序列）。

由于物体形状通常不是规则的四边形，常用的 `grid` 或 `sequence` 结构处理起图像来不够灵活，所以在本文中采用 `graph` 结构。

### 1.2 3种模型

- `CNN`：曾经是计算机视觉中的主流网络结构，已经成功地应用于各种视觉任务，如图像分类、物体检测和语义分割。CNN模型在过去的十年里发展迅速，代表性的模型包括ResNet、MobileNet和NAS。
- `Vision transformer`：从2020年开始，被引入到视觉任务中，ViT的一些变体开始被提出来以提高视觉任务的性能。主要的改进包括金字塔结，局部注意和位置编码。
- `MLP`：通过专门设计的模块，MLP可以达到有竞争力的性能，并且在一般的视觉任务（如物体检测和分割）上工作。

### 1.3 GNN模型

**1. GNN&GCN**

> `GNN`：图神经网络，由于传统的CNN网络无法表示顶点和边这种关系型数据，便出现了图神经网络解决这种图数据的表示问题，这属于CNN往图方向的应用扩展
>
> `GCN`：图卷积神经网络，GNN在训练过程中，有将attention引入图结构的，有将门控机制引入图结构的，还有将卷积引入图结构的，引入卷积的GNN就是GCN，通过提取空间特征来进行学习

**2. 发展**

Micheli提出了早期的提出了早期的基于空间的GCN，Bruna等人提出了基于频谱的GCN，近几年来基于这两种GCN的改进和扩展也被提出。

**3. 应用**

GCN通常被应用于图数据，如社会网络、引文网络和生化图；在计算机视觉领域的应用主要包括点云分类、场景图生成和动作识别。

GCN只能解决自然形成的图的特定视觉任务，对于计算机视觉的一般应用，我们需要一个基于GCN的骨干网络来直接处理图像数据。

## 2 ViG模型

### 2.1 模型构建

#### Image→Graph

首先基于 `graph `  结构建立视觉图形神经网络，用于视觉任务。将输入的图像划分为若干个 `patches`（补丁），并将每个斑块视为一个 `node` （节点）。[^4]

[^4]: 不用像素当做节点的原因：会导致节点过多

.

对于一个大小为 $H×W×3$ 的图像，我们将其分为 N 个补丁，把每个补丁转化为一个特征向量 $x_i∈R^D$，得到 $X = [x_1,x_2,...,x_N ]$， 其中 $D$ 是特征维度。将特征看做无序节点$V={v_1,v_2,...,v_N}$，节点$v_i$的k邻近节点记为$N(v_i)$，对每个$v_j∈N(v_i)$添加$v_j$到$v_i$的边$e_ji$。

最终得到图$G = (V,E) $，我们把图的构建过程记为$G = G(X)$。

#### 图层处理

图卷积层可以通过聚合其邻居节点的特征在节点之间交换信息。具体操作方式为：

$G' = F(G, W)=Update(Aggregate(G, W_agg), W_update) $ 

其中，$W_agg$和 $W_update$是聚合、更新操作的可学习权重。

> **聚合**：通过聚合邻居节点的特征来计算一个节点的表征
>
> **更新**：进一步合并聚合的特征

通过**最大相对卷积**处理图层面，记为$X' = GraphConv(X)$。

$x_i' = h(x_i, g(x_i, N(x_i), W_agg), W_update)$

$g(·) = x_i'' = [x_i, max(${$x_j - x_i|j∈N(x_i)$}]

$h(·) = x_i' = x_i''W_update$

.

接着进行图卷积的**多头更新操作**（有利于特征多样性），将聚合后的特征 $x_i''$ 分割成 $h$ 个头，然后分别以不同的权重更新这些头，得到：

$x_i' = [head^1W^1update, head^2W^2update,...head^hW^hupdate]$

#### ViG block

> **ViG的2个基本模块**
>
> **Graph模块**：是在图卷积的基础上构建的，用于聚合和更新图形信息，可以缓解传统GNN的过度平滑现象
>
> **FFN模块**：带有两个线性层，用于节点特征转换和鼓励节点多样性

以前的GCN通常重复使用卷积层来提取图形数据的聚合特征，这会导致**过度平滑**的现象 ，降低节点特征的显著性，如下图所示所示。为了解决这个问题，本文在ViG块中引入了更多的**特征转换**和**非线性激活**。

![image3](/img/GNN/image3.png)

我们在图卷积前后应用一个**线性层**，将节点特征投射到同一领域，增加特征多样性。在图卷积之后插入一个**非线性激活函数**以避免层崩溃。我们称升级后的模块为**Grapher模块**，给定输入特征$X∈R^N×^D$  ，则可得到：$Y = σ(GraphConv(XW_in))W_out + X$  [^1]

[^1]: 最后加上 $X$​ 是残差连接，为了避免过拟合。

.

其中$W_in$和$W_out$是全连接层的权重，σ是激活函数。为了进一步提高特征转换能力，我们在每个节点上利用**前馈网络（FFN）**：$Z = σ(YW_1)W_2 + Y$

其中$W_1$和$W_2$是全连接层的权重。Graph模块和FFN模块的堆叠构成了ViG块，作为构建网络的基本单元。基于图像的**graph结构**和**ViG块**，我们可以建立ViG网络。
![image2](/img/GNN/image2.png)

### 2.2 网络框架

> 各项同性结构：指主体在整个网络中具有同等大小和形状的特征
> 金字塔结构：考虑了图像的多尺度特性，提取特征的空间大小逐渐变小

在计算机视觉领域，常用的结构有各向同性结构和金字塔结构。为了与其他类型的神经网络有更普遍的比较，文章分别为ViG建立了这两种网络结构。

#### 各向同性结构

文章建立了3个大小不同的各向同性ViG架构。为了扩大感受野，邻居结点的数量K从9线性增加到18；头的数量被设定为 h = 4。详情如下表：[^2]

[^2]: FLOPs：浮点运算数，可以用来衡量算法/模型的复杂度。

![image4](/img/GNN/image4.png)

#### 金字塔结构

文章建立了4个大小不同的金字塔ViG模型。详情如下：[^3]

![image5](/img/GNN/image5.png)

[^3]: E是FNN中的隐藏维度

#### 位置编码

为了表示节点的位置信息，文章为每个节点特征添加一个位置向量：$x_i←x_i+e_i$ ；金字塔结构中可以进一步使用相对位置编码。

### 2.3 模型优点

- `graph` 是广义的数据结构，`grid` 和 `sequence` 可以看做 `graph` 的特例
- `graph` 更灵活，可以对复杂、不规则的物体进行建模
- 一个物体可以被看作是由各个部分组成的，`graph` 结构可以构建他们的联系

## 3 实验

> **top1  accuracy**：预测的label取最后概率向量里面最大的那一个作为预测结果，如果预测结果中概率最大的分类正确，则预测正确，否则预测错误。
>
> **top5  accuracy**：最后概率向量最大的前五名中，只要出现了正确概率即为预测正确，否则预测错误。

### 3.1 实验结果

本文分别将各向同性结构、金字塔结构的ViG与同样结构的CNN、转化器和 MLPs对比，可以看出：

- 将图片视作Graph能够在计算机视觉任务中取得非常好的结果
- 和各向同性结构相比，金字塔结构的ViG具有更好的性能

各向同性结构的实验结果：

![image6](/img/GNN/image6.png)

金字塔结构的实验结果：

![image7](/img/GNN/image7.png)

### 3.2 消融研究

> 消融研究：通过删除部分网络并研究网络的性能来更好的了解网络。

文章以各向同性的ViG-Ti为基础架构，在ImageNet分类任务上进行了消融研究，结果如下：

- 通过改变图卷积的类型，发现不同图卷积的Top-1准确率很高，说明ViG架构的灵活性。其中，最大相对卷积在计算量和精度之间实现了最佳的权衡。
- 直接利用图卷积进行图像分类的效果很差，可以通过添加更多的特征转换，如引入FC和FFN不断提高准确性。
- 太少的邻居结点会降低信息交流，太多会导致过度平滑。当邻居节点的数量在9-15的范围时表现较好。
- 头的数量 h=4时，计算量和精度可以最好平衡。

### 3.3 可视化

为了更好地理解本文的ViG模型是如何工作的，作者可视化了构建的图结构，展示了两个不同深度的样本的图。五角星是中心节点，相同颜色的节点是其邻居。



可以看到，在浅层，邻居节点往往是根据低层次、局部特征来选择的，如颜色和纹理；在深层层中，中心节点的邻居更具语义性，属于同一类别。而本文的ViG网络可以通过其内容和语义表征逐渐将节点联系起来，并帮助更好地识别物体。

![image8](/img/GNN/image8.png)



参考资料：

[从图(Graph)到图卷积(Graph Convolution)：漫谈图神经网络模型 (一)](https://www.cnblogs.com/SivilTaram/p/graph_neural_network_1.html)

[图卷积神经网络(GCN)](https://blog.csdn.net/liuweiyuxiang/article/details/98957612)

[GRAPH CONVOLUTIONAL NETWORKS](http://tkipf.github.io/graph-convolutional-networks/)






