<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>深度学习 - Tag - 菜菜的秘密花园</title>
        <link>https://imcaicai.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link>
        <description>深度学习 - Tag - 菜菜的秘密花园</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Fri, 18 Nov 2022 23:33:29 &#43;0800</lastBuildDate><atom:link href="https://imcaicai.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="self" type="application/rss+xml" /><item>
    <title>Label Embedding Online Hashing for Cross-Modal Retrieval</title>
    <link>https://imcaicai.github.io/lemon/</link>
    <pubDate>Fri, 18 Nov 2022 23:33:29 &#43;0800</pubDate>
    <author>菜菜</author>
    <guid>https://imcaicai.github.io/lemon/</guid>
    <description><![CDATA[本文为论文 Label Embedding Online Hashing for Cross-Modal 的阅读笔记。
论文下载：https://doi.org/10.1145/3394171.3413971
1 简介 学习散列，作为最著名的近似近邻搜索技术之一，近年来吸引了很多人的注意。它旨在将高维实值特征映射到紧凑的二进制编码，同时保留原始空间中的相似性。然后，可以用XOR操作在Hamming空间中进行搜索，效率高，存储成本低。
许多跨模态散列方法已经被提出并取得了很好的性能。但大多数现有的方法通过批处理学习二进制代码或哈希函数。即在学习过程前，所有的训练数据都可用。这将产生以下问题：
 实际数据通常以流方式收集，有新数据到来时，批处理方法需要对所有数据重新训练 → 效率低 训练集随训练时间变大 → 计算成本高  为了解决这些问题，在线散列被提出，但仍存在问题：
 大多数在线散列方法是为单模态检索设计的，很难直接扩展到跨模态检索。少数在线跨模态散列模型被提出，但性能较差，因为异质模态之间的关联性难以捕捉。 只根据新到达的数据更新散列函数，忽略了新旧数据间的相关性 → 丢失现有数据的信息 → 现有在线散列。 新数据到来时，哈希函数可以有效地重新训练，但哈希码必须对所有累积数据重构 → 更新方案低效。 离散优化大多采用松弛策略 → 量化误差大。  为了解决上述问题，这篇文章提出了一种新的监督下的跨模式检索的在线散列方法，即Label EMbedding ONline hashing，简称LEMON。本文的主要贡献总结如下：
  提出了一种新的有监督的在线散列检索方法，即LEMON。  它通过一个标签嵌入框架来捕捉语义结构，其中包括标签相似性的保存和标签重构，从而得到更有辨识度的二进制码。 通过优化内积最小化问题将新旧数据的哈希码连接起来，解决了更新不平衡问题。 采用两步学习策略，有效地更新哈希函数和二进制码，同时保持旧数据库的哈希代码不可更改，使其计算复杂度仅与流数据的大小有关。   提出了一种迭代优化算法来离散地解决二进制优化问题，极大地减少 量化误差。 在三个基准数据集上的实验结果表明，LEMON在跨模式检索任务上优于一些先进的离线和在线散列方法，并且可以扩展到大规模数据集。   2 相关工作 现有工作存在的问题：
 单模态：不能直接用于跨模态检索任务；必须在每一轮更新所有的二进制代码，效率非常低 多模态：不能跨模态检索 跨模态：不能充分利用原始特征、语义标签；不能很好地以流的方式来捕捉数据的相似性信息   单模态：查询和要检索的文档都只有一个模态（图像→图像）
多模态：查询和要检索的文档必须至少有一个模态相同（图像、文本→图像、文本）
跨模态：查询和要检索的文档模态不同（图像→文本）
 3 方法 3.1 Notations 假设每个样本由 $l$ 个模态组成。在第 $t$ 轮，一个新的数据块 $\vec{X}^{(t)}$ 被添加到数据库中。常用变量的说明如下：]]></description>
</item>
<item>
    <title>Vision GNN: An Image is Worth Graph of Nodes</title>
    <link>https://imcaicai.github.io/an-image-is-worth-graph-of-nodes/</link>
    <pubDate>Mon, 17 Oct 2022 00:00:00 &#43;0000</pubDate>
    <author>菜菜</author>
    <guid>https://imcaicai.github.io/an-image-is-worth-graph-of-nodes/</guid>
    <description><![CDATA[本文为论文 Vision GNN: An Image is Worth Graph of Nodes 的阅读笔记。
论文下载：https://arxiv.org/abs/2206.00272
引言 网络架构在基于深度学习的计算机视觉中起着关键作用。广泛使用的CNN和 transformer（变换器）将图像视为 grid（网格）或 sequence（序列）结构，这对于捕捉不规则、复杂的物体来说是不灵活的。本文建议将图像表示为一个 graph 结构，并引入一个新的 Vision GNN（ViG）架构来提取视觉任务的图层特征。
文章主要工作：
 介绍了计算机视觉方面的现有模型方法和成果 介绍ViG模型的构建过程及工作原理，为未来的研究提供有用的灵感和经验 通过图像分类和物体检测实验证明了ViG模型在视觉任务中的有效性  1 相关研究 CNN 曾经是计算机视觉中标准的网络结构，但近来 transformer with attention mechanism 、MLP-based 等模型也在不断发展，这些正在将视觉模型推向一个前所未有的高度。
1.1 3种图像结构 不同的网络结构以不同的方式处理输入的图像，通常有grid, sequence ,graph 3种，如下图所示。在 grid  和 sequence 结构中，节点只按空间位置排序；在 graph 结构中，节点是通过其内容连接的，不受局部位置的限制。
CNN 在图像上应用滑动窗口，并引入移位变异性和位置性；最近的 vision transformer 或 MLP 将图像视为 a sequence of patches（补丁序列）。
由于物体形状通常不是规则的四边形，常用的 grid 或 sequence 结构处理起图像来不够灵活，所以在本文中采用 graph 结构。
1.2 3种模型  CNN：曾经是计算机视觉中的主流网络结构，已经成功地应用于各种视觉任务，如图像分类、物体检测和语义分割。CNN模型在过去的十年里发展迅速，代表性的模型包括ResNet、MobileNet和NAS。 Vision transformer：从2020年开始，被引入到视觉任务中，ViT的一些变体开始被提出来以提高视觉任务的性能。主要的改进包括金字塔结，局部注意和位置编码。 MLP：通过专门设计的模块，MLP可以达到有竞争力的性能，并且在一般的视觉任务（如物体检测和分割）上工作。  1.]]></description>
</item>
</channel>
</rss>
